{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_to_df (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This program uses the boostrapping approach to estimate the parameters of an ODE system.\n",
    "using Pkg, NBInclude, Plots, XLSX, Dates, DataFrames, Random, Statistics\n",
    "using DifferentialEquations, Sundials, ForwardDiff, Optim\n",
    "using Distributions, ProgressMeter, Distributed, StaticArrays, LaTeXStrings\n",
    "@nbinclude(\"ODE_models.ipynb\")\n",
    "#@nbinclude(\"Norm_functions.ipynb\")\n",
    "@nbinclude(\"ODE_Fit.ipynb\")\n",
    "@nbinclude(\"ODE_Fit_IPN.ipynb\")\n",
    "@nbinclude(\"HelperFunctions.ipynb\")\n",
    "#@nbinclude(\"More_helpers.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODE_Param_Est (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ODE_Param_Est(;ODE_model::Function, ODE_vars::Array{Symbol}, vars_to_fit::Array{Symbol},\n",
    "                        paramIC_dict::Dict, data_dict::Dict, f_calc_ICs::Function, func_sim_data::Function,\n",
    "                        fit_range::Array{String,1}, date_obs_last::String, forecast_until::String, N0::Real,\n",
    "                        norm::Function, norm_weights::Array{Real,1} = fill(1.0,1e6), norm_scale::Real = 1.0,\n",
    "                        optimizer::Any = ConjugateGradient(), constraints::Dict = Dict(), func_get_x0::Function,\n",
    "                        BS_samples::Int64 = 1, num_x0::Int64 = 1, pred_band_pct = 90, x_pctiles::Array,\n",
    "                        integrator_options::Dict, optimizer_options::Dict, save_options::Dict)\n",
    "   \n",
    "    \n",
    "    #############################################\n",
    "    #STEP 0: Some Error Handling and other stuff\n",
    "    #############################################\n",
    "    \n",
    "    if !(issubset(Set(vars_to_fit), Set(ODE_vars)))\n",
    "        error(\"Error: vars_to_fit must be a subset of ODE_vars\")\n",
    "    end\n",
    "    \n",
    "    if (pred_band_pct < 0 || pred_band_pct > 100)\n",
    "        error(\"Error: pred_band_pct must be in [0,100]\")\n",
    "    end\n",
    "    \n",
    "    if (minimum(x_pctiles) < 0 || maximum(x_pctiles) > 100)\n",
    "        error(\"Error: x_pctiles can only contain values in [0,100]\")\n",
    "    end\n",
    "     \n",
    "    #Create an array of the variables (Symbols) NOT fitted\n",
    "    vars_not_fit = collect(setdiff(Set(ODE_vars), Set(vars_to_fit)))\n",
    "    \n",
    "    #The arguments related to saving the outputs\n",
    "    save_figs = get(save_options, :save_figs, true)  #defaults to true\n",
    "    save_params = get(save_options, :save_params, true) #defaults to true\n",
    "    figs_folder = get(save_options, :figs_folder, \"C:/Users/Michael/Documents/COVID-19/BS_plots/\")\n",
    "    params_folder = get(save_options, :params_workbook, \"C:/Users/Michael/Documents/COVID-19/test.xlsx\")\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    #STEP 1: Parse the Observed (*Real*) Data \n",
    "    ##############################################\n",
    "    \n",
    "    #Get the file path of the Excel Workbook\n",
    "    data_path = get(data_dict, :file_path, \"data_path is invalid\")\n",
    "    \n",
    "    #Get the name of the spreadsheet containing the observed data\n",
    "    data_sheet = get(data_dict, :data_sheet, \"data_sheet is invalid\")\n",
    "    \n",
    "    #Get the format of the dates in the spreadsheet (default is \"mm-dd-yyyy\")\n",
    "    date_format = get(data_dict, :date_format, \"mm-dd-yyyy\")\n",
    "    \n",
    "    #Read in the Excel workbook\n",
    "    xf_data = XLSX.readxlsx(data_path)\n",
    "    \n",
    "    #Select the spreadsheet\n",
    "    data_obs = xf_data[data_sheet]\n",
    "    \n",
    "    #Put the spreadsheet data into a DataFrame\n",
    "    data_obs_all = DataFrame(XLSX.gettable(data_obs, header = true)...)\n",
    " \n",
    "    #Convert the first column to the \"Date\" type \n",
    "    data_obs_all[!,1] = convert.(Date, data_obs_all.Date)\n",
    "  \n",
    "    #Create Date objects for the first and last days to be fitted\n",
    "    date_fit_first, date_fit_last = Date.(fit_range[1:2], date_format)\n",
    "    \n",
    "    #Convert date_obs_last from a String to a Date\n",
    "    date_obs_last = Date(date_obs_last, date_format)\n",
    "    \n",
    "    #Convert forecast_until from a String to a Date\n",
    "    date_pred_last = Date(forecast_until, date_format)\n",
    "    \n",
    "    #Find the row numbers of date_fit_first, date_fit_last, date_obs_last\n",
    "    local row_fit_first::Int64 \n",
    "    local row_fit_last::Int64   \n",
    "    local row_obs_last::Int64\n",
    "    \n",
    "    try \n",
    "        row_fit_first = findall(data_obs_all.Date .== date_fit_first)[1]\n",
    "    catch\n",
    "        error(\"Error: The first date in fit_range was not found in the spreadsheet.\")\n",
    "    end\n",
    "    try\n",
    "        row_fit_last = findall(data_obs_all.Date .== date_fit_last)[1]\n",
    "    catch\n",
    "        error(\"Error: The second date in fit_range was not found in the spreadsheet.\")\n",
    "    end\n",
    "    try \n",
    "        row_obs_last = findall(data_obs_all.Date .== date_obs_last)[1]\n",
    "    catch\n",
    "        error(\"Error: The date entered for data_obs_last was not found in the spreadsheet.\")\n",
    "    end\n",
    "    \n",
    "    #The dates for the *fitted* data\n",
    "    dates_fit = data_obs_all.Date[row_fit_first:row_fit_last]\n",
    "\n",
    "    #The dates of *not* fitted but observed data that we want to plot at the very end\n",
    "    dates_nf = data_obs_all.Date[row_fit_last+1:row_obs_last]\n",
    "    \n",
    "    #The observed data that will be fitted (does not include the Date column)\n",
    "    data_obs_fit = data_obs_all[row_fit_first:row_fit_last, vars_to_fit]\n",
    "  \n",
    "    #The observed data that will *NOT* fitted, but *will be plotted*\n",
    "    data_obs_nf = data_obs_all[row_fit_last+1:row_obs_last, vars_to_fit]\n",
    "    \n",
    "    #Note 2/5/21: No need to scale the data here because ODE_Fit takes care of this. \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    #STEP 2: Convert the Dates to Integer values\n",
    "    ##############################################\n",
    "   \n",
    "    #Note: The t values here are the number of days since date_first.\n",
    "    \n",
    "    #Calculate the Rata Die value of date_first\n",
    "    t0_rata = Dates.datetime2rata(date_fit_first)\n",
    "    \n",
    "    #The t values for the data to be *fitted*\n",
    "    t_fit = Array{Float64}(Dates.datetime2rata.(dates_fit) .- t0_rata)\n",
    "    \n",
    "    #The t values for the data *not* fitted \n",
    "    t_nf = Array{Float64}(Dates.datetime2rata.(dates_nf) .- t0_rata)\n",
    "    \n",
    "    #Calculate the Rata Die value of date_pred_last\n",
    "    t_pred_last = Dates.datetime2rata(date_pred_last) - t0_rata\n",
    "    \n",
    "    #All t values for which we'll solve & plot the ODE at the very end \n",
    "    t_all = collect(0.0:1:t_pred_last)\n",
    "    #2/5/21: Maybe make the step size smaller to get a denser solution? \n",
    "    \n",
    "    \n",
    "    #########################################\n",
    "    #STEP 3: Parse the Parameter and IC Data\n",
    "    #########################################\n",
    "    \n",
    "    #Get the path of the Excel workbook containing the Param & IC data\n",
    "    ParIC_path = get(paramIC_dict, :file_path, \"Par/IC file_path not found\")\n",
    "    \n",
    "    #Get the names of the parameter & IC sheets\n",
    "    param_sheet = get(paramIC_dict, :param_sheet, \"param_sheet not found\")\n",
    "    IC_sheet = get(paramIC_dict, :IC_sheet, \"IC_sheet not found\")\n",
    "    \n",
    "    #Read in the Excel workbook\n",
    "    xf_ParIC = XLSX.readxlsx(ParIC_path)\n",
    "    \n",
    "    #Get the Excel sheets \n",
    "    param_wkst = xf_ParIC[param_sheet]\n",
    "    IC_wkst = xf_ParIC[IC_sheet]\n",
    "    \n",
    "    #Put the worksheet data into DataFrames \n",
    "    param_df = DataFrame(XLSX.gettable(param_wkst, header = true)...,)\n",
    "    IC_df = DataFrame(XLSX.gettable(IC_wkst, header = true)...,)\n",
    "\n",
    "    #Rename the columns of par_data and IC_df (just in case)\n",
    "    rename!(param_df,[\"Parameter\",\"Fixed?\",\"Lower Bound\",\"Initial Guess\",\"Upper Bound\",\"Interpretation\"])\n",
    "    rename!(IC_df,[\"IC\",\"Fixed?\",\"Lower Bound\",\"Initial Guess\",\"Upper Bound\",\"Interpretation\"])\n",
    "\n",
    "    param_opt_names = param_df[param_df.\"Fixed?\" .== \"No\", 1]\n",
    "    IC_opt_names = IC_df[IC_df.\"Fixed?\" .== \"No\", 1]\n",
    "    x_names = convert.(String, [param_opt_names; IC_opt_names])\n",
    "    \n",
    "    #Specify the column types \n",
    "    col_types = [String, String, Real, Real, Real, String]\n",
    "    for i=1:6\n",
    "        param_df[!,i] = convert.(Union{Missing,col_types[i]}, param_df[:,i])\n",
    "        IC_df[!,i] = convert.(Union{Missing,col_types[i]}, IC_df[:,i])\n",
    "    end\n",
    "\n",
    "    #Get the indices of the different groups (fixed/optimized, params/ICs)\n",
    "    param_opt_indices = findall(param_df[:,\"Fixed?\"] .== \"No\")\n",
    "    param_fix_indices = findall(param_df[:,\"Fixed?\"] .== \"Yes\")\n",
    "    IC_opt_indices = findall(IC_df[:,\"Fixed?\"] .== \"No\")\n",
    "    IC_fix_indices = findall(IC_df[:,\"Fixed?\"] .== \"Yes\")\n",
    "\n",
    "    #Get number of params, ICs of each type \n",
    "    num_params_opt = length(param_opt_indices)\n",
    "    num_params_fix = length(param_fix_indices)\n",
    "    num_ICs_opt = length(IC_opt_indices)       #(really the number of ICs/IC ratios)\n",
    "    num_ICs_fix = length(IC_fix_indices)       #(really the number of ICs/IC ratios)\n",
    "    \n",
    "    num_vars_opt = num_params_opt + num_ICs_opt\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    #STEP 4: Get the box constraints for the optimized values and *scale* them\n",
    "    ############################################################################\n",
    "    \n",
    "    #Lower Bounds (optimized parameters)\n",
    "    param_LBs = param_df[param_df.\"Fixed?\" .== \"No\", \"Lower Bound\"]\n",
    "    param_UBs = param_df[param_df.\"Fixed?\" .== \"No\", \"Upper Bound\"]\n",
    "    \n",
    "    #Lower Bounds (optimized ICs/IC ratios)\n",
    "    IC_LBs = IC_df[IC_df.\"Fixed?\" .== \"No\", \"Lower Bound\"]\n",
    "    IC_UBs = IC_df[IC_df.\"Fixed?\" .== \"No\", \"Upper Bound\"]\n",
    "    \n",
    "    #All UBs (to pass to ODE_fit)\n",
    "    UBs = [param_UBs; IC_UBs]  #Array{Union{Missing, Float64},1}\n",
    "    \n",
    "    #Scaled Lower Bounds (optimized parameters)\n",
    "    param_LBs_scaled = param_LBs ./ param_UBs\n",
    "    param_UBs_scaled = repeat([1.], length(param_UBs))\n",
    "    \n",
    "    #Scaled Lower Bounds (optimized ICs/IC ratios)\n",
    "    IC_LBs_scaled = IC_LBs ./ IC_UBs\n",
    "    IC_UBs_scaled = repeat([1.], length(IC_UBs))\n",
    "    \n",
    "    #The Lower & Upper Bound arrays for the optimizer\n",
    "    x_LBs = [param_LBs_scaled; IC_LBs_scaled]     #Array{Float64,1}\n",
    "    x_UBs = [param_UBs_scaled; IC_UBs_scaled]     #Array{Float64,1}\n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    #STEP 5: Get all the FIXED values and put them in an array\n",
    "    ###########################################################\n",
    "    \n",
    "    #Get all the fixed values from the spreadsheet\n",
    "    params_fix = param_df[param_df.\"Fixed?\" .== \"Yes\", \"Initial Guess\"]\n",
    "    ICs_fix = IC_df[IC_df.\"Fixed?\" .== \"Yes\", \"Initial Guess\"]\n",
    "    \n",
    "    #All the fixed parameters/ICs in the objectivefrom the spreadsheet function\n",
    "    fixed_args = Array{Real}([params_fix; ICs_fix])\n",
    "\n",
    "    num_params = num_params_opt + num_params_fix       #The total number of params\n",
    "    num_ICs_and_IC_ratios = num_ICs_opt + num_ICs_fix  #The total number of ICs/IC ratios in the spreadsheet\n",
    "     \n",
    "    \n",
    "    ##########################################################\n",
    "    #STEP 6: Generate a list of random initial guesses\n",
    "    ##########################################################\n",
    "    \n",
    "    #Get the initial guesses given in the spreadsheet\n",
    "    par_init_first = param_df[param_df.\"Fixed?\" .== \"No\", \"Initial Guess\"]\n",
    "    IC_init_first = IC_df[IC_df.\"Fixed?\" .== \"No\", \"Initial Guess\"]\n",
    "\n",
    "    #Generate list of random initial guesses\n",
    "    Random.seed!(1234) #set seed for reproducibility\n",
    "    x0_list = [func_get_x0(x_LBs, x_UBs) for i=1:num_x0]\n",
    "    x0_list[1] = [par_init_first; IC_init_first] ./ UBs    \n",
    "  \n",
    "    #Note: We use the initial guesses in the spreadsheet as the first x0 value.\n",
    "\n",
    "    ##########################################\n",
    "    #STEP 7: Generate the Simulated Data Sets \n",
    "    ##########################################\n",
    "    \n",
    "    Random.seed!(5678)  #Set seed for reproducibility\n",
    "    sim_data_list = [func_sim_data(data_obs_fit) for i=1:BS_samples]\n",
    "    sim_data_list[1] = data_obs_fit  \n",
    "    #Note: We use the original (observed) data set as the first one to fit\n",
    "  \n",
    "    \n",
    "    #####################################################################\n",
    "    #STEP 8: Get all of the options for the optimization and integration\n",
    "    #####################################################################\n",
    "    \n",
    "    local opt_alg::Any\n",
    "    \n",
    "    #Choose which function to call depending on the chosen optimizer...add options for LBFGS and BFGS?\n",
    "    if optimizer == ConjugateGradient\n",
    "        fit_ODE = FirstOrderFit\n",
    "        opt_alg = ConjugateGradient()\n",
    "    elseif optimizer == GradientDescent\n",
    "        fit_ODE = FirstOrderFit\n",
    "        opt_alg = GradientDescent()\n",
    "    elseif optimizer == IPNewton\n",
    "        fit_ODE = SecondOrderFit\n",
    "        opt_alg = IPNewton()\n",
    "    else\n",
    "        error(\"Error: You entered an invalid optimizer!\")\n",
    "    end\n",
    "    \n",
    "    #The options for Optim.Options()\n",
    "    xtol_abs = get(optimizer_options, :xtol_abs, 1e-10)\n",
    "    ftol_rel = get(optimizer_options, :ftol_rel, 1e-4)\n",
    "    gtol_abs = get(optimizer_options, :gtol_abs, 1e-8)\n",
    "    max_iter = get(optimizer_options, :max_iter, 1000)\n",
    "    max_time = get(optimizer_options, :max_time, 3000)\n",
    "    show_trace = get(optimizer_options, :show_trace, true)\n",
    "    show_every = get(optimizer_options, :show_every, 5)\n",
    "    \n",
    "    optim_options = Optim.Options(x_tol = xtol_abs, f_tol = ftol_rel, g_tol = gtol_abs, iterations = max_iter, \n",
    "                                  time_limit = max_time,  show_trace = show_trace, show_every = show_every, \n",
    "                                  allow_f_increases = true, successive_f_tol = 4)\n",
    "   \n",
    "    #The constraints for Optim\n",
    "    con_func = constraints[:con_func]\n",
    "    con_jac = constraints[:con_jac]\n",
    "    con_hess = constraints[:con_hess]\n",
    "    con_LBs = constraints[:con_LBs]\n",
    "    con_UBs = constraints[:con_UBs]\n",
    "    cons = TwiceDifferentiableConstraints(con_func, con_jac, con_hess, x_LBs, x_UBs, con_LBs, con_UBs)\n",
    "    \n",
    "    #Collect optim_options, cons, and (almost) all of the other options for ODE_Fit\n",
    "    fit_args = (ODE_model = ODE_model,\n",
    "                ODE_vars = ODE_vars,\n",
    "                t_obs = t_fit, \n",
    "                t_all = t_all,\n",
    "                x_LBs = x_LBs,\n",
    "                x_UBs = x_UBs,\n",
    "                UBs = UBs,\n",
    "                param_opt_indices = param_opt_indices, \n",
    "                param_fix_indices = param_fix_indices,\n",
    "                IC_opt_indices = IC_opt_indices,\n",
    "                IC_fix_indices = IC_fix_indices,\n",
    "                params_fix = params_fix, \n",
    "                ICs_fix = ICs_fix, \n",
    "                f_calc_ICs = f_calc_ICs,\n",
    "                N0 = N0,\n",
    "                norm = norm,\n",
    "                norm_weights = norm_weights,\n",
    "                norm_scale = norm_scale,\n",
    "                optimizer = opt_alg,\n",
    "                make_plots = false,\n",
    "                constraints = cons,\n",
    "                integrator_options = integrator_options,\n",
    "                optim_options = optim_options,\n",
    "                convergence_report = false)\n",
    "    \n",
    "    \n",
    "    ##############################################################\n",
    "    #STEP 9: Create some arrays for storing optimization output\n",
    "    #######  and a couple other set-up things.\n",
    "    ##############################################################\n",
    "    \n",
    "    minimums_all = []    #store all the minimum objective values found\n",
    "    minimizers_all = []   #stores all the sets of parameters obtained via the optimizations\n",
    "    \n",
    "    minimums_best = []   #the best mininums found for each data set\n",
    "    minimizers_best = []  #stores the best set of parameters found for each simulated data set\n",
    "    \n",
    "    soln_dfs = [] #List to hold solutions (as DataFrames) for each tuple in minimizers_best\n",
    "    \n",
    "    autodiff_fails = 0    #to keep track of number of times autodifferentiation failed \n",
    "    sample_num = 1\n",
    "    \n",
    "    #Display progress bar\n",
    "    p = Progress(num_x0 * BS_samples, 1, \"Optimizations in progress...\", 50)\n",
    "\n",
    "    \n",
    "    ###############################################################\n",
    "    #STEP 10: Perform the Optimizations on the simulated data sets\n",
    "    ###############################################################\n",
    "    \n",
    "    #Loop over the simulated data sets\n",
    "    t = @elapsed for sim_data in sim_data_list \n",
    "        \n",
    "        minimums_sample = []    #to store the obj func values for each sample\n",
    "        minimizers_sample = []  #to store the minimizers of each sample\n",
    "       \n",
    "        #Loop over the initial guesses\n",
    "        for x0 in x0_list\n",
    "            \n",
    "            optim_out = fit_ODE(;fit_args...,x0 = x0, data_obs = sim_data, autodiff = :forward)\n",
    "             \n",
    "            #Check the type of the output if it errors\n",
    "            if (typeof(optim_out.minimum) != Float64) || (typeof(optim_out.minimizer) != Array{Float64,1}) \n",
    "                println(\"Uh oh, there was an error: typeof(optim_out.minimum) = \", typeof(optim_out.minimum))\n",
    "                println(\"Uh oh, there was an error: typeof(optim_out.minimizer) = \", typeof(optim_out.minimizer))\n",
    "            else\n",
    "                push!(minimums_sample, optim_out.minimum)     #Add the obj func value to the list\n",
    "                push!(minimizers_sample, optim_out.minimizer) #Add the minimizer to the list\n",
    "                push!(minimums_all, optim_out.minimum)        #Add the minimum to the \"master\" list\n",
    "                push!(minimizers_all, optim_out.minimizer)    #Add the minimizer to the \"master\" list \n",
    "\n",
    "                if optim_out.AD_fail == true\n",
    "                    autodiff_fails += 1\n",
    "                end\n",
    "            end\n",
    "                \n",
    "            next!(p) #Update the progress bar \n",
    "        end\n",
    "        \n",
    "        best_minimum = minimum(minimums_sample)                   #Get best minimum found from the sample\n",
    "        idx_best = findall(minimums_sample .== best_minimum)[1]   #Get the index of the best minimium/minimizer  \n",
    "        best_minimizer = minimizers_sample[idx_best]              #Get the best minimizer from the sample\n",
    "        \n",
    "        push!(minimums_best, best_minimum)       #Add the best minimium from the sample to the list of best minimums\n",
    "        push!(minimizers_best, best_minimizer)   #Add the best minimizer from the sample to the list of best minimizers\n",
    "     \n",
    "        println(\"Sample \", sample_num, \" best min: \", best_minimum)\n",
    "        sample_num += 1\n",
    "        \n",
    "    end\n",
    "    \n",
    "\n",
    "    #To do: report total optimization time in hrs, mins, seconds\n",
    "    println(\"\\nTotal optimization time: \", round(t), \" seconds\")\n",
    "    println(\"Average time per optimization: \", round(t / (num_x0 * BS_samples), sigdigits = 4), \" seconds\\n\")\n",
    "    println(\"Number of autodiff fails: \", autodiff_fails,\"\\n\")\n",
    "    \n",
    "    ##########################################################################################\n",
    "    #STEP 11: Compute the ODE solutions for the best minimizers (to make the prediction bands)\n",
    "    ##########################################################################################\n",
    "      \n",
    "    soln_dfs = []  #List to store DataFrames containing the solutions.\n",
    "    \n",
    "    for i=1:BS_samples\n",
    "        x_best = minimizers_best[i]\n",
    "        sol = ODE_sol(ODE_model, ODE_vars, x_best, params_fix, ICs_fix, param_opt_indices, \n",
    "                      param_fix_indices, IC_opt_indices, IC_fix_indices, param_UBs, IC_UBs, f_calc_ICs, \n",
    "                      N0, t_all, int_options)  #Get the solution for the best minimizer of the i-th sample\n",
    "        push!(soln_dfs,sol)\n",
    "    end\n",
    "    \n",
    "    #Make a dictionary of the solutions organized by *variable*\n",
    "    var_dfs = sort_by_var(soln_dfs)\n",
    "    \n",
    "    ###########################################################\n",
    "    #STEP 12: Compute the percentiles for the prediction bands\n",
    "    ###########################################################\n",
    "    \n",
    "    band_pct_low  = (50 - pred_band_pct/2)/100     #Lowest percentile to plot\n",
    "    band_pct_high = (50 + pred_band_pct/2)/100     #Highest percentile to plot\n",
    "    band_pct_med = 0.50                              \n",
    "    #Note: We divide the percentiles by 100 b.c. percentiles_by_row() expects numbers in [0,1] \n",
    "   \n",
    "    #Dictionary to store variable percentile data.\n",
    "    var_pctiles_dict = Dict()   #Dict will store one DataFrame for each ODE variable.  \n",
    "    \n",
    "    #Get DataFrame of percentiles for each variable and store it in dictionary \n",
    "    for var in ODE_vars\n",
    "        df = select(var_dfs[var], Not(:t))   \n",
    "        pctiles_df = percentiles_by_row(df; low = band_pct_low, med = band_pct_med, high = band_pct_high) \n",
    "        insertcols!(pctiles_df, 1, :t => t_all)  #Add the t column back in\n",
    "        var_pctiles_dict[var] = pctiles_df\n",
    "    end\n",
    "    \n",
    "    #############################################################\n",
    "    #STEP 13: Plot the prediction band for each fitted variable. \n",
    "    #############################################################\n",
    "    \n",
    "    #Convert the first date fitted to a string in the desired format (for labelling the plots)\n",
    "    date_str_first = Dates.format(date_fit_first, date_format)\n",
    "    \n",
    "    for var in vars_to_fit\n",
    "        \n",
    "       #Select the DataFrame of percentiles\n",
    "       var_pctiles_df  = var_pctiles_dict[var]\n",
    "        \n",
    "       #Get the values for each percentile\n",
    "       var_pct_low  = var_pctiles_df[:,string(band_pct_low)]\n",
    "       var_pct_med  = var_pctiles_df[:,string(band_pct_med)]\n",
    "       var_pct_high = var_pctiles_df[:,string(band_pct_high)]\n",
    "        \n",
    "       #Plot the prediction band (aka \"cloud\")\n",
    "       fig = plot(t_all, var_pct_low, fillrange = var_pct_high, fillalpha = 0.25, c = 4, lw = 0,\n",
    "                  label = \"$(pred_band_pct)% prediction band\",\n",
    "                  xlabel = L\"t \\textrm{ (days since %$date_str_first)}\",\n",
    "                  ylabel = \"Number\",\n",
    "                  legend = :topleft, \n",
    "                  title = L\"%$var\",\n",
    "                  fontfamily=\"serif-roman\",\n",
    "                  dpi = 90)\n",
    "      \n",
    "        \n",
    "       ##################################################################\n",
    "       #STEP 14: Plot the observed data (on top of the prediction bands)\n",
    "       ##################################################################\n",
    "        \n",
    "       #Plot the fitted observed data\n",
    "       plot!(t_fit, data_obs_fit[:,var],\n",
    "             line = :scatter,\n",
    "             ms = 2,           #markersize\n",
    "             msw = 0,          #markerstrokewidth\n",
    "             label = L\"%$var \\textrm{ (observed, fit)}\")\n",
    "       \n",
    "       #Plot the not fitted observed data\n",
    "       plot!(t_nf, data_obs_nf[:,var],\n",
    "             line = :scatter,\n",
    "             ms = 2,\n",
    "             msw = 0,\n",
    "             label = L\"%$var \\textrm{ (observed, not fit)}\")\n",
    "      \n",
    "       display(fig)   #display the figure in the notebook \n",
    "        \n",
    "       ##########################################################################\n",
    "       #STEP 15: Save the plots to the specified file path (if save_figs == true)\n",
    "       ##########################################################################\n",
    "       if save_figs == true\n",
    "          plot!(fig, dpi = 300)   #save using high resolution\n",
    "          path = figs_folder * string(var) * \".png\"\n",
    "          savefig(fig, path)\n",
    "       end\n",
    "        \n",
    "        #For some reason, setting dpi > 100 causes the plot display to be HUGE. \n",
    "        #Strangely, increasing the dpi increases the figure dimensions as well as the resolution...Why?\n",
    "    end #vars in vars_to_fit  \n",
    "        \n",
    "\n",
    "#     #################################################################\n",
    "#     #STEP 16: Plot the prediction bands for the NOT fitted variables\n",
    "#     #################################################################\n",
    "    \n",
    "#     for var in vars_not_fit\n",
    "        \n",
    "#        #Select the DataFrame of percentiles\n",
    "#        var_pctiles_df  = var_pctiles_dict[var]\n",
    "        \n",
    "#        #Get the values for each percentile\n",
    "#        var_pct_low  = var_pctiles_df[:,string(band_pct_low)]\n",
    "#        var_pct_med  = var_pctiles_df[:,string(band_pct_med)]\n",
    "#        var_pct_high = var_pctiles_df[:,string(band_pct_high)]\n",
    "        \n",
    "#        #Plot the prediction band (aka \"cloud\")\n",
    "#        fig = plot(t_all, var_pct_low, fillrange = var_pct_high, fillalpha = 0.25, c = 4, lw = 0,\n",
    "#                   label = \"$(pred_band_pct)% prediction band\",\n",
    "#                   xlabel = L\"t \\textrm{ (days since %$date_str_first)}\",\n",
    "#                   ylabel = \"Number\",\n",
    "#                   legend = :topleft, \n",
    "#                   title = L\"%$var\",\n",
    "#                   fontfamily=\"serif-roman\")\n",
    "    \n",
    "#        display(fig)   \n",
    "            \n",
    "#        if save_figs == true\n",
    "#           plot!(fig, dpi = 300)   #save using high resolution\n",
    "#           path = figs_folder * string(var) * \".png\"\n",
    "#           savefig(fig, path)\n",
    "#        end \n",
    "       \n",
    "#     end #for vars in vars_not_fit\n",
    "    \n",
    "    ########################################################\n",
    "    #STEP 17: Organize the best minimizers into a DataFrame\n",
    "    ########################################################\n",
    "    \n",
    "    #Organize the BEST minimizers in a DataFrame\n",
    "    minimizers_df = DataFrame(Array{Float64}(undef, length(minimizers_best), length(x_names)), x_names);\n",
    "    \n",
    "    for i=1:length(minimizers_best)\n",
    "        minimizers_df[i,:] = UBs .* minimizers_best[i]   #Note that we scale the values back\n",
    "    end\n",
    "\n",
    "    #########################################################################\n",
    "    #STEP 18: Create DataFrame of percentiles based on the *best* minimizers\n",
    "    #########################################################################\n",
    "        \n",
    "    #The column names (percentile values) for our percentile DataFrame\n",
    "    str_pctiles = [string(p) for p in x_pctiles]\n",
    "    \n",
    "    #Create an empty DataFrame to store the percentile data \n",
    "    par_pctiles = DataFrame(Array{Float64}(undef, length(x_names), length(str_pctiles)), str_pctiles)\n",
    "    \n",
    "    for i=1:length(x_names)\n",
    "        par_pctiles[i,:] = quantile(minimizers_df[:,i], (x_pctiles ./ 100))\n",
    "    end\n",
    "    \n",
    "    #Insert a column for the parameter/IC names \n",
    "    insertcols!(par_pctiles, 1, :Parameter => x_names)\n",
    "    \n",
    "    #Insert a column for the objective function value at each minimum \n",
    "    insertcols!(minimizers_df, 1, :obj_value => minimums_best)\n",
    "    \n",
    "    ###############################################################################\n",
    "    #STEP 19: Return the parameter percentiles DataFrame and a couple other values.\n",
    "    ############################################################################### \n",
    "    println(par_pctiles)\n",
    "    return (minimizers_df = minimizers_df, var_pctiles_dict = var_pctiles_dict,\n",
    "            data_obs_fit = data_obs_fit, data_obs_nf = data_obs_nf, t_all = t_all, \n",
    "            t_fit = t_fit, t_nf = t_nf, x0_list = x0_list, sim_data_list = sim_data_list)\n",
    "\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
